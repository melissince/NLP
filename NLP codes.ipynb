{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11132\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = []\n",
    "date = []\n",
    "title=[]\n",
    "topic=[]\n",
    "article=[]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/Users/melisince/Desktop/text analytics/Comp-Text-Analysis-2018-19-master/datasets/dataset.tsv',\n",
    "                         sep='\\t', header=0) #I downloaded the tsv file as a pandas dataframe and I informed python that the file is tab seperated by using sep='\\t'\n",
    "#so now it is going to be easy to extract the specific columns from the dataframe by their name.\n",
    "data.columns=['date','title','topic','content'] #here I renamed the name of the columns because I was not sure if columns are called as they are written on the tsv file\n",
    "\n",
    "data=data.iloc[1:] #above header=0 did not exclude the header row, so I tried this iloc. \n",
    "\n",
    "wordcount=data['content'].str.split().str.len() #the words are splitted by the white spaces, however the numbers and special characters like \n",
    "#twitter links or photo links for the articles are counted as a word here. \n",
    "\n",
    "data['wordcount']=wordcount #Here I created a new column called 'wordcount' and put the word counting of the content column into the wordcount column\n",
    "\n",
    "data=pd.DataFrame(data[data.wordcount>6]) #dropped the articles which have wordcounts less than 6. from now on, contents with longer than 6 words are going to be in article corpus.\n",
    "\n",
    "#here I assign each column to its so called list.\n",
    "article=data.content.tolist() \n",
    "title=data.title.tolist()\n",
    "date=data.date.tolist()\n",
    "topic=data.topic.tolist()\n",
    "\n",
    "print(len(article)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting point:\n",
    "\n",
    "Take your corpus and topic lists.\n",
    "\n",
    "Train 1 type of topic classifier of your choice (among naive-bayes, knn and NearestCentroid) using pre-trained word embeddings to generate the feature-vector.\n",
    "\n",
    "Task:\n",
    "\n",
    "Compare the performance (always using 10 fold cross validation!) of at least 2 different pre-processing steps (for instance lemmatization vs non-lemmatization, stopword removal or not, only using NER instead of using lemmas, only using nouns, only using name of organizations).\n",
    "\n",
    "Present here:\n",
    "\n",
    "The two different text_embedding functions you used (example, a pipeline where you use lemmatization and one without lemmatization);\n",
    "The cross-validation experiment, showing the different outputs in terms of precision, recall and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /anaconda3/lib/python3.6/site-packages (3.6.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /anaconda3/lib/python3.6/site-packages (from gensim) (1.11.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /anaconda3/lib/python3.6/site-packages (from gensim) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /anaconda3/lib/python3.6/site-packages (from gensim) (1.14.3)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /anaconda3/lib/python3.6/site-packages (from gensim) (1.7.1)\n",
      "Requirement already satisfied: boto>=2.32 in /anaconda3/lib/python3.6/site-packages (from smart-open>=1.2.1->gensim) (2.48.0)\n",
      "Requirement already satisfied: requests in /anaconda3/lib/python3.6/site-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
      "Requirement already satisfied: bz2file in /anaconda3/lib/python3.6/site-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
      "Requirement already satisfied: boto3 in /anaconda3/lib/python3.6/site-packages (from smart-open>=1.2.1->gensim) (1.9.25)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /anaconda3/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /anaconda3/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda3/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim) (2018.4.16)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.25 in /anaconda3/lib/python3.6/site-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.25)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /anaconda3/lib/python3.6/site-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /anaconda3/lib/python3.6/site-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /anaconda3/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.25->boto3->smart-open>=1.2.1->gensim) (2.7.3)\n",
      "Requirement already satisfied: docutils>=0.10 in /anaconda3/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.25->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install gensim #gensim is a library famous for word embeddings and semantics\n",
    "\n",
    "import gensim, logging\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('/Users/melisince/Desktop/text analytics/Comp-Text-Analysis-2018-19-master/resources/small-embeddings.txt', binary=False)\n",
    "\n",
    "import nltk, string #nltk is for the tokenization and string is for extracting the punctuation.\n",
    "from nltk.corpus import stopwords #I want to remove the stopwords which makes it easier for the function to clean the articles.. \n",
    "from nltk.stem.wordnet import WordNetLemmatizer #for the lemmatization. \n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) #list of punctuations to remove them\n",
    "stop_word_list = stopwords.words('english') #extracting the list of stopwords in english.\n",
    "\n",
    "\n",
    "def text_embedding_first(text):\n",
    "    \n",
    "    text = nltk.word_tokenize(text)#tokenization\n",
    "    text = [token for token in text if token not in exclude and token.isalpha()]#removing characters that are not words in english and removing the punctuations. \n",
    "    text = [token for token in text if token not in stop_word_list] #keeping the words which are not in stop words lists\n",
    "    text = nltk.pos_tag(text) #pos tagging for lemmatization \n",
    "    text = [wordnet_lemmatizer.lemmatize(token,\"v\") if pos[0] == \"V\" else wordnet_lemmatizer.lemmatize(token) for token,pos in text] #lemmatization \n",
    "    article_embedd = [] #wcreating an empty list for the word embeddings.\n",
    "    #the for loop below will do the word embedding depending on the word2vec model\n",
    "    for word in text: \n",
    "            try:\n",
    "                embed_word = model[word] #model is the vocab of word embeddings where words are associated with word embeddings. \n",
    "                article_embedd.append(embed_word)\n",
    "            except KeyError:\n",
    "                continue\n",
    "    avg = [float(sum(col))/len(col) for col in zip(*article_embedd)] #average vectors of all words in the articles. this is the column wise average. \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "#creating first corpus for the text embedding with lemmatization and removed stopwords. \n",
    "corpusfirst = []\n",
    "\n",
    "for word in article:\n",
    "    emb_text = text_embedding_first(word) #word embeddings are created. \n",
    "    if len(emb_text) > 0: #take the articles with word embeddings bigger than zero.\n",
    "        corpusfirst.append(emb_text)\n",
    "    \n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11132\n"
     ]
    }
   ],
   "source": [
    "print(len(corpusfirst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /anaconda3/lib/python3.6/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /anaconda3/lib/python3.6/site-packages (from sklearn) (0.19.1)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:553: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.47454354863390136, 0.536035178065942, 0.4823216023002924, None)\n",
      "(0.5111812796680445, 0.5513811702834961, 0.5128340418878011, None)\n",
      "(0.592252326817665, 0.6330349598758672, 0.5916261631234289, None)\n",
      "(0.5426847050813826, 0.5688324115477217, 0.529202420834845, None)\n",
      "(0.49014867867145523, 0.5208082740711054, 0.48132121039483966, None)\n",
      "(0.52623601653576, 0.5552772617867748, 0.5148950420417192, None)\n",
      "(0.5604681122454368, 0.655441114067207, 0.5698649734002443, None)\n",
      "(0.5193255845493087, 0.5506725464111979, 0.5113872293898842, None)\n",
      "(0.5270620003157697, 0.5555850660196245, 0.5146447809393302, None)\n",
      "(0.42435940998586896, 0.44277215377981854, 0.4121870778921966, None)\n",
      " \n",
      "0.5120284542204582\n",
      "0.5168261662504592\n",
      "0.5168261662504592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# I use np array as they are more efficient\n",
    "X = np.array(corpusfirst)\n",
    "y = np.array(topic)\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "final_f1first = [] \n",
    "final_precisionfirst=[]\n",
    "final_recallfirst=[]\n",
    "\n",
    "#we set that we do 10 fold cross validation\n",
    "\n",
    "kf_total = cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True)\n",
    "\n",
    "for train, test in kf_total:\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    \n",
    "    classifier = GaussianNB().fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print (precision_recall_fscore_support(y_test, y_pred, average=\"macro\")) #if you are only interested in positive values, macro average between the two classes.\n",
    "    f1_score = precision_recall_fscore_support(y_test, y_pred, average=\"macro\")[2]\n",
    "    precision_score = precision_recall_fscore_support(y_test, y_pred, average=\"macro\")[0]\n",
    "    recall_score = precision_recall_fscore_support(y_test, y_pred, average=\"macro\")[1]\n",
    "    final_f1first.append(f1_score)\n",
    "    final_precisionfirst.append(precision_score)\n",
    "    final_recallfirst.append(precision_score)\n",
    "print (\" \")\n",
    "print (sum(final_f1first)/len(final_f1first))\n",
    "print (sum(final_precisionfirst)/len(final_precisionfirst))\n",
    "print (sum(final_recallfirst)/len(final_recallfirst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the second text preprocessing function without lemmatization\n",
    "def text_embedding_second(text):\n",
    "    \n",
    "    #here I tokenized the each word for the preprocessign the articles. \n",
    "    text = nltk.word_tokenize(text)\n",
    "    text = [token for token in text if token not in exclude and token.isalpha()]#removing characters that are not words in english and removing the punctuation basically. \n",
    "    text = [token for token in text if token not in stop_word_list] #keeping the words which are not in stop words lists\n",
    "    article_embedd = []\n",
    "\n",
    "    for word in text: \n",
    "            try:\n",
    "                embed_word = model[word] #model is the vocab of word embeddings where words are associated with word embeddings. \n",
    "                article_embedd.append(embed_word)\n",
    "            except KeyError:\n",
    "                continue\n",
    "    avg = [float(sum(col))/len(col) for col in zip(*article_embedd)] #average vectors of all words. this is the column wise average. this represent the meaning of your document.\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "corpussecond = []\n",
    "\n",
    "for word in article:\n",
    "    emb_text = text_embedding_second(word) \n",
    "    if len(emb_text) > 0:\n",
    "        corpussecond.append(emb_text)\n",
    "    \n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:553: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5213164243418563, 0.5444049524159026, 0.5075616326822531, None)\n",
      "(0.5489818638644993, 0.5682009340998503, 0.5363153263259005, None)\n",
      "(0.5252300090145604, 0.5702324942201641, 0.5219464976888859, None)\n",
      "(0.5304272106782718, 0.5703952992878674, 0.530456077759527, None)\n",
      "(0.5341906146007918, 0.5657281412659783, 0.5259583690697713, None)\n",
      "(0.5521343256751966, 0.6498443443027301, 0.5534561834865527, None)\n",
      "(0.46615233836597686, 0.502412022694008, 0.46612346630351614, None)\n",
      "(0.5436595607358959, 0.5786126948575565, 0.5354904633043461, None)\n",
      "(0.5061562127161328, 0.5395705969387871, 0.5027989114308732, None)\n",
      "(0.5564193093780203, 0.6287818205973289, 0.5597676889283619, None)\n",
      " \n",
      "0.5239874616979988\n",
      "0.5284667869371201\n",
      "0.5718183300680173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# I use np array as they are more efficient\n",
    "X = np.array(corpussecond)\n",
    "y = np.array(topic)\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "final_f1second = []\n",
    "final_precisionsecond=[]\n",
    "final_recallsecond=[]\n",
    "#we set that we do 10 fold cross validation\n",
    "\n",
    "kf_total = cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True)\n",
    "\n",
    "for train, test in kf_total:\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    \n",
    "    classifier = GaussianNB().fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print (precision_recall_fscore_support(y_test, y_pred, average=\"macro\")) #if you are only interested in positive values, macro average between the two classes.\n",
    "    f1_score = precision_recall_fscore_support(y_test, y_pred, average=\"macro\")[2]\n",
    "    precision= precision_recall_fscore_support(y_test, y_pred, average=\"macro\")[0]\n",
    "    recall=precision_recall_fscore_support(y_test, y_pred, average=\"macro\")[1]\n",
    "    final_f1second.append(f1_score)\n",
    "    final_precisionsecond.append(precision)\n",
    "    final_recallsecond.append(recall)\n",
    "print (\" \")\n",
    "print (sum(final_f1second)/len(final_f1second)) #the average of fscore\n",
    "print(sum(final_precisionsecond)/len(final_precisionsecond)) #the average of precision\n",
    "print(sum(final_recallsecond)/len(final_recallsecond))#the average of recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the precision, recall and f1 scores are changing between two texts which shows that text preprocessing matters. \n",
    "#Without lemmatization in the second text preprocessing, the precision, f1 and recall scores shows better performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take your corpus list.\n",
    "\n",
    "Task:\n",
    "\n",
    "Lemmatize the corpus, remove stopwords and lemmas shorter than 5 characters. Then convert each article in a document embedding.\n",
    "\n",
    "Group documents in 10 clusters using k-means.\n",
    "\n",
    "Counts how many documents you have, for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stop_word_list = stopwords.words('english') \n",
    "\n",
    "def text_embedding_third(text):\n",
    "    \n",
    "    text = nltk.word_tokenize(text)#here I tokenized the each word for the preprocessign the articles.\n",
    "    text = [token for token in text if token not in stop_word_list] #keeping the words which are not in stop words lists\n",
    "    text = nltk.pos_tag(text)\n",
    "    text = [wordnet_lemmatizer.lemmatize(token,\"v\") if pos[0] == \"V\" else wordnet_lemmatizer.lemmatize(token) for token,pos in text] \n",
    "    lemma_article=[] #here the list will contain lemma longer than 5 characters. \n",
    "    for lemma in text:\n",
    "        if len(lemma)>5:\n",
    "            lemma_article.append(lemma)\n",
    "    article_embedd = [] #I want to use our vocabulary of word embeddings\n",
    "# for each word in the article, I take the embeddings. I have a gigantic list of word embeddings of each word. I simply do a column wise average. then I have your doc embedding.\n",
    "    for word in lemma_article: \n",
    "            try:\n",
    "                embed_word = model[word] #model is the vocab of word embeddings where words are associated with word embeddings. \n",
    "                article_embedd.append(embed_word)\n",
    "            except KeyError:\n",
    "                continue\n",
    "    avg = [float(sum(col))/len(col) for col in zip(*article_embedd)] #average vectors of all words. this is the column wise average. \n",
    "    return avg\n",
    "\n",
    "corpusthird = []\n",
    "\n",
    "for word in article:\n",
    "    emb_text = text_embedding_third(word) #this function does all the things we have learnt throughout the lecture. in the exam, when you do text preprocessing write a function that takes your string into a vector.\n",
    "    if len(emb_text) > 0:\n",
    "        corpusthird.append(emb_text)\n",
    "    \n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11121\n"
     ]
    }
   ],
   "source": [
    "print(len(corpusthird))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans #here is the library for KMeans. \n",
    "import numpy as np\n",
    "k = 10 #setting the number of cluster\n",
    "x = np.array(corpusthird)\n",
    "model = KMeans(k, init='k-means++', max_iter=100, n_init=1).fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 1840, 3: 1803, 5: 1552, 8: 1483, 7: 966, 4: 947, 6: 914, 0: 850, 9: 485, 1: 281})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter,defaultdict #counting the documents in each cluster. \n",
    "print(Counter(model.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take your corpus list.\n",
    "\n",
    "Task:\n",
    "\n",
    "Lemmatize the corpus and keep only the nouns.\n",
    "\n",
    "Run LDA topic models with 50 topics.\n",
    "\n",
    "Feed the results into pyLDAvis to visualize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the pipeline for the lemmatization of the nouns.\n",
    "def text_lemma(text):\n",
    "    tokentext = nltk.word_tokenize(text)\n",
    "    \n",
    "    cleantext = [token for token in tokentext if token not in exclude and token.isalpha()]\n",
    "\n",
    "    pos_text = nltk.pos_tag(cleantext)\n",
    "    \n",
    "    nouns= [] #the list of the nouns.\n",
    "    for word,pos in pos_text:\n",
    "        if (pos==\"NN\" or pos == \"NNP\" or pos==\"NNS\" or pos==\"NNPS\"):\n",
    "            nouns.append(word)\n",
    "    lemmatext = [wordnet_lemmatizer.lemmatize(token) for token in nouns]\n",
    "    \n",
    "    return(lemmatext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmano=[]#the final list that I will use in the LDA model dictionary\n",
    "for word in article:\n",
    "    lemmanouns=text_lemma(word)\n",
    "    lemmano.append(lemmanouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['READ', 'MORE', 'plane', 'football', 'team', 'crash', 'Colombia', 'report', 'Ronaldinho', 'Argentina', 'star', 'Juan', 'Roman', 'Riquelme', 'club', 'Football', 'Ronaldinho', 'Juan', 'Roman', 'Riquelme', 'retirement', 'play', 'Chapecoensehttps', 'Ronaldinho', 'honor', 'playing', 'career', 'World', 'Cup', 'Riquelme', 'time', 'Argentina', 'country', 'player', 'year', 's', 'brother', 'agent', 'Roberto', 'Assis', 'Ronaldinho', 'club', 'way', 'discussion', 'place', 'time', 'Assis', 'Globo', 'Esporte', 'Later', 'contact', 'Ronaldinho', 'profile', 'guy', 'moment', 'family', 'expectation', 'Brazilians', 'plane', 'crash', 'people', 'club', 's', 'player', 'A', 'player', 'Danilo', 'hospital', 'wreckage', 'FIFA', 'president', 'Gianni', 'Infantino', 'funeral', 'Chapecoense', 'player', 'Friday', 'trip', 'Australia', 'woman', 'World', 'Cup', 'crash', 'world', 'UEFA', 'president', 'Aleksander', 'Ceferin', 'condolence', 'week', 'Champions', 'League', 'Europa', 'League', 'game', 's', 'silence', 'player', 'armband', 'READ', 'MORE', 'Chapecoense', 'plane', 'crash', 'Crew', 'Brazilian', 'team', 's', 'flight', 'time', 'football', 'sympathy', 'Football', 'Confederation', 'CBF', 'CONMEBOL', 'family', 'victim', 'week', 'air', 'disaster', 'Ceferin', 'statement', 'tragedy', 'world', 'football', 'support']\n"
     ]
    }
   ],
   "source": [
    "print(lemmano[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models #the packages are downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready!\n"
     ]
    }
   ],
   "source": [
    "#For each article in the corpus, creating a dictionary \n",
    "dictionary = corpora.Dictionary(lemmano) \n",
    "A = [dictionary.doc2bow(text) for text in lemmano]\n",
    "print(\"ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "ldamodel = models.ldamodel.LdaModel(A, num_topics=50, id2word = dictionary, iterations=1000) \n",
    "print (\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, '0.030*\"photo\" + 0.023*\"A\" + 0.020*\"PDT\" + 0.018*\"GIPHY\" + 0.011*\"bear\" + 0.011*\"project\" + 0.009*\"PST\" + 0.009*\"technology\" + 0.007*\"year\" + 0.007*\"park\" + 0.007*\"Oct\" + 0.007*\"Instagram\" + 0.005*\"program\" + 0.005*\"world\" + 0.005*\"s\" + 0.005*\"design\" + 0.005*\"cloud\" + 0.004*\"brain\" + 0.004*\"team\" + 0.004*\"animal\" + 0.004*\"time\" + 0.004*\"visitor\" + 0.004*\"Nov\" + 0.003*\"Park\" + 0.003*\"vehicle\" + 0.003*\"Technology\" + 0.003*\"manufacturer\" + 0.003*\"efficiency\" + 0.003*\"Algiers\" + 0.003*\"engineer\"')\n",
      "(10, '0.040*\"UK\" + 0.036*\"EU\" + 0.034*\"Britain\" + 0.021*\"Brexit\" + 0.016*\"referendum\" + 0.015*\"Cameron\" + 0.010*\"vote\" + 0.009*\"s\" + 0.009*\"people\" + 0.008*\"Minister\" + 0.008*\"country\" + 0.008*\"minister\" + 0.008*\"leader\" + 0.008*\"Prime\" + 0.008*\"David\" + 0.007*\"London\" + 0.007*\"Europe\" + 0.007*\"member\" + 0.006*\"European\" + 0.006*\"PM\" + 0.006*\"government\" + 0.006*\"year\" + 0.006*\"May\" + 0.005*\"Johnson\" + 0.005*\"campaign\" + 0.005*\"time\" + 0.005*\"Parliament\" + 0.005*\"MP\" + 0.005*\"decision\" + 0.004*\"petition\"')\n",
      "(17, '0.039*\"Russia\" + 0.015*\"US\" + 0.012*\"Putin\" + 0.011*\"country\" + 0.009*\"government\" + 0.008*\"people\" + 0.008*\"RT\" + 0.008*\"Ukraine\" + 0.007*\"Moscow\" + 0.007*\"Syria\" + 0.007*\"year\" + 0.007*\"group\" + 0.007*\"percent\" + 0.006*\"United\" + 0.006*\"UN\" + 0.006*\"MORE\" + 0.006*\"READ\" + 0.005*\"s\" + 0.005*\"President\" + 0.005*\"Russian\" + 0.005*\"war\" + 0.005*\"election\" + 0.005*\"Russians\" + 0.005*\"party\" + 0.005*\"conflict\" + 0.005*\"sanction\" + 0.005*\"part\" + 0.004*\"situation\" + 0.004*\"Vladimir\" + 0.004*\"state\"')\n",
      "(6, '0.016*\"gun\" + 0.010*\"delegate\" + 0.010*\"state\" + 0.009*\"California\" + 0.007*\"year\" + 0.007*\"Austria\" + 0.007*\"Cruz\" + 0.007*\"convention\" + 0.007*\"people\" + 0.006*\"Carolina\" + 0.006*\"Hofer\" + 0.006*\"Scott\" + 0.005*\"s\" + 0.005*\"RT\" + 0.005*\"vote\" + 0.004*\"percent\" + 0.004*\"firearm\" + 0.004*\"time\" + 0.004*\"Georgia\" + 0.004*\"Ohio\" + 0.004*\"Kasich\" + 0.004*\"Islamophobia\" + 0.004*\"http\" + 0.004*\"Bellator\" + 0.003*\"Alexander\" + 0.003*\"voter\" + 0.003*\"Bahraini\" + 0.003*\"permit\" + 0.003*\"item\" + 0.003*\"Kenya\"')\n",
      "(19, '0.011*\"marijuana\" + 0.010*\"sport\" + 0.008*\"IAAF\" + 0.008*\"Olympic\" + 0.007*\"France\" + 0.007*\"attack\" + 0.007*\"police\" + 0.006*\"year\" + 0.006*\"ban\" + 0.006*\"Nice\" + 0.005*\"church\" + 0.005*\"people\" + 0.004*\"Association\" + 0.004*\"Fury\" + 0.004*\"READ\" + 0.004*\"time\" + 0.004*\"MORE\" + 0.004*\"decision\" + 0.004*\"state\" + 0.004*\"s\" + 0.004*\"Interior\" + 0.004*\"athlete\" + 0.004*\"Carson\" + 0.004*\"country\" + 0.003*\"National\" + 0.003*\"Twitter\" + 0.003*\"November\" + 0.003*\"Rice\" + 0.003*\"authority\" + 0.003*\"Athletics\"')\n",
      "(7, '0.077*\"Turkey\" + 0.022*\"Turkish\" + 0.021*\"Ankara\" + 0.020*\"border\" + 0.019*\"Erdogan\" + 0.007*\"Istanbul\" + 0.007*\"oil\" + 0.007*\"Yildirim\" + 0.007*\"student\" + 0.006*\"Syria\" + 0.005*\"country\" + 0.005*\"Kurdish\" + 0.005*\"Recep\" + 0.004*\"Square\" + 0.004*\"spacecraft\" + 0.004*\"agency\" + 0.004*\"Tayyip\" + 0.004*\"State\" + 0.004*\"Islamic\" + 0.004*\"RT\" + 0.004*\"people\" + 0.004*\"number\" + 0.004*\"government\" + 0.004*\"IS\" + 0.004*\"group\" + 0.004*\"tire\" + 0.004*\"day\" + 0.004*\"Monday\" + 0.003*\"Davutoglu\" + 0.003*\"President\"')\n",
      "(32, '0.018*\"NASA\" + 0.018*\"space\" + 0.012*\"Earth\" + 0.012*\"water\" + 0.012*\"mile\" + 0.010*\"storm\" + 0.010*\"Mars\" + 0.008*\"Lake\" + 0.008*\"pipeline\" + 0.008*\"surface\" + 0.008*\"Space\" + 0.007*\"river\" + 0.007*\"s\" + 0.007*\"scientist\" + 0.006*\"field\" + 0.006*\"Dakota\" + 0.006*\"cat\" + 0.006*\"Tesla\" + 0.006*\"lake\" + 0.006*\"weather\" + 0.006*\"temperature\" + 0.006*\"year\" + 0.005*\"Pipeline\" + 0.005*\"car\" + 0.005*\"foot\" + 0.005*\"spill\" + 0.005*\"ring\" + 0.005*\"system\" + 0.004*\"time\" + 0.004*\"site\"')\n",
      "(38, '0.021*\"police\" + 0.018*\"woman\" + 0.013*\"s\" + 0.010*\"assault\" + 0.010*\"men\" + 0.010*\"man\" + 0.010*\"city\" + 0.009*\"girl\" + 0.008*\"Year\" + 0.008*\"Park\" + 0.008*\"New\" + 0.007*\"Germany\" + 0.007*\"Cologne\" + 0.007*\"RT\" + 0.007*\"refugee\" + 0.006*\"people\" + 0.006*\"time\" + 0.006*\"case\" + 0.006*\"medium\" + 0.006*\"year\" + 0.005*\"report\" + 0.005*\"number\" + 0.005*\"sex\" + 0.005*\"asylum\" + 0.005*\"MORE\" + 0.005*\"attack\" + 0.005*\"READ\" + 0.005*\"Eve\" + 0.004*\"victim\" + 0.004*\"Post\"')\n",
      "(23, '0.028*\"Snowden\" + 0.025*\"Afghanistan\" + 0.013*\"NSA\" + 0.013*\"Taliban\" + 0.011*\"Afghan\" + 0.010*\"state\" + 0.010*\"US\" + 0.009*\"drone\" + 0.009*\"Pakistan\" + 0.008*\"pardon\" + 0.008*\"Rousseff\" + 0.007*\"Brazil\" + 0.006*\"government\" + 0.006*\"abortion\" + 0.006*\"s\" + 0.006*\"woman\" + 0.006*\"strike\" + 0.006*\"worker\" + 0.006*\"health\" + 0.006*\"Supreme\" + 0.005*\"National\" + 0.005*\"Court\" + 0.005*\"year\" + 0.005*\"impeachment\" + 0.004*\"alcohol\" + 0.004*\"insurance\" + 0.004*\"report\" + 0.004*\"law\" + 0.004*\"Kabul\" + 0.004*\"Act\"')\n",
      "(48, '0.017*\"people\" + 0.008*\"s\" + 0.007*\"wave\" + 0.006*\"year\" + 0.006*\"movement\" + 0.006*\"book\" + 0.005*\"group\" + 0.005*\"time\" + 0.005*\"protest\" + 0.004*\"reform\" + 0.004*\"way\" + 0.004*\"memory\" + 0.004*\"universe\" + 0.003*\"city\" + 0.003*\"name\" + 0.003*\"National\" + 0.003*\"government\" + 0.003*\"law\" + 0.003*\"bill\" + 0.003*\"police\" + 0.003*\"Cox\" + 0.003*\"place\" + 0.003*\"country\" + 0.003*\"Black\" + 0.003*\"veteran\" + 0.003*\"community\" + 0.003*\"homeless\" + 0.003*\"MORE\" + 0.002*\"idea\" + 0.002*\"demonstration\"')\n",
      "(0, '0.043*\"NO\" + 0.034*\"video\" + 0.027*\"protester\" + 0.027*\"RT\" + 0.027*\"motion\" + 0.023*\"agency\" + 0.021*\"PLEASE\" + 0.021*\"FOR\" + 0.021*\"RUPTLY\" + 0.021*\"COURTESY\" + 0.021*\"LICENSING\" + 0.021*\"REUSE\" + 0.021*\"CONTACT\" + 0.015*\"protest\" + 0.015*\"police\" + 0.012*\"http\" + 0.012*\"camp\" + 0.010*\"rally\" + 0.010*\"Calais\" + 0.009*\"street\" + 0.008*\"demonstration\" + 0.008*\"people\" + 0.007*\"city\" + 0.007*\"crowd\" + 0.007*\"A\" + 0.007*\"Saturday\" + 0.006*\"demonstrator\" + 0.006*\"gas\" + 0.005*\"activist\" + 0.005*\"Thursday\"')\n",
      "(12, '0.022*\"athlete\" + 0.014*\"case\" + 0.012*\"Olympic\" + 0.011*\"court\" + 0.011*\"decision\" + 0.011*\"WADA\" + 0.011*\"Russia\" + 0.011*\"report\" + 0.010*\"IOC\" + 0.009*\"s\" + 0.008*\"Rio\" + 0.008*\"sport\" + 0.008*\"Olympics\" + 0.007*\"Games\" + 0.007*\"ban\" + 0.007*\"Committee\" + 0.007*\"investigation\" + 0.007*\"Court\" + 0.007*\"allegation\" + 0.007*\"McLaren\" + 0.007*\"team\" + 0.006*\"statement\" + 0.006*\"year\" + 0.006*\"drug\" + 0.006*\"lawyer\" + 0.006*\"evidence\" + 0.005*\"International\" + 0.005*\"time\" + 0.005*\"test\" + 0.005*\"US\"')\n",
      "(14, '0.039*\"China\" + 0.027*\"US\" + 0.014*\"RT\" + 0.010*\"country\" + 0.009*\"Russia\" + 0.008*\"South\" + 0.008*\"s\" + 0.008*\"Sea\" + 0.008*\"year\" + 0.007*\"medium\" + 0.006*\"Beijing\" + 0.006*\"America\" + 0.006*\"news\" + 0.006*\"Washington\" + 0.005*\"island\" + 0.005*\"Vietnam\" + 0.005*\"BBC\" + 0.004*\"view\" + 0.004*\"Iran\" + 0.004*\"war\" + 0.004*\"world\" + 0.004*\"Karlov\" + 0.004*\"Chinese\" + 0.004*\"base\" + 0.004*\"part\" + 0.004*\"region\" + 0.004*\"time\" + 0.004*\"government\" + 0.004*\"opinion\" + 0.003*\"statement\"')\n",
      "(15, '0.019*\"Libya\" + 0.012*\"country\" + 0.008*\"group\" + 0.008*\"government\" + 0.007*\"IS\" + 0.007*\"people\" + 0.007*\"party\" + 0.007*\"s\" + 0.007*\"Syria\" + 0.007*\"Serbia\" + 0.006*\"year\" + 0.006*\"Gaddafi\" + 0.006*\"State\" + 0.005*\"Islamic\" + 0.005*\"law\" + 0.005*\"member\" + 0.005*\"Germany\" + 0.004*\"state\" + 0.004*\"Minister\" + 0.004*\"Islam\" + 0.004*\"number\" + 0.004*\"force\" + 0.004*\"De\" + 0.004*\"Libyan\" + 0.003*\"time\" + 0.003*\"MORE\" + 0.003*\"AfD\" + 0.003*\"authority\" + 0.003*\"READ\" + 0.003*\"support\"')\n",
      "(35, '0.027*\"attack\" + 0.016*\"people\" + 0.015*\"police\" + 0.009*\"man\" + 0.008*\"security\" + 0.006*\"Paris\" + 0.006*\"incident\" + 0.006*\"A\" + 0.006*\"year\" + 0.006*\"suspect\" + 0.006*\"scene\" + 0.006*\"time\" + 0.005*\"s\" + 0.005*\"place\" + 0.005*\"day\" + 0.005*\"bus\" + 0.005*\"ship\" + 0.005*\"car\" + 0.004*\"truck\" + 0.004*\"city\" + 0.004*\"Police\" + 0.004*\"area\" + 0.004*\"woman\" + 0.004*\"Navy\" + 0.004*\"READ\" + 0.004*\"MORE\" + 0.004*\"video\" + 0.004*\"Islamic\" + 0.004*\"France\" + 0.004*\"authority\"')\n",
      "(29, '0.020*\"gold\" + 0.016*\"medal\" + 0.012*\"player\" + 0.011*\"competition\" + 0.010*\"sample\" + 0.009*\"Ronaldo\" + 0.009*\"arm\" + 0.008*\"NHL\" + 0.008*\"Secret\" + 0.007*\"year\" + 0.007*\"world\" + 0.007*\"tournament\" + 0.006*\"Bolt\" + 0.006*\"Canada\" + 0.006*\"World\" + 0.006*\"star\" + 0.005*\"team\" + 0.005*\"Russia\" + 0.005*\"sale\" + 0.005*\"Finland\" + 0.005*\"Group\" + 0.005*\"Rio\" + 0.004*\"Olympic\" + 0.004*\"brand\" + 0.004*\"record\" + 0.004*\"time\" + 0.004*\"silver\" + 0.004*\"Service\" + 0.004*\"Ovechkin\" + 0.004*\"Rose\"')\n",
      "(4, '0.022*\"Aleppo\" + 0.016*\"force\" + 0.014*\"city\" + 0.014*\"area\" + 0.013*\"Syria\" + 0.011*\"attack\" + 0.011*\"civilian\" + 0.011*\"terrorist\" + 0.011*\"people\" + 0.011*\"US\" + 0.010*\"militant\" + 0.010*\"Iraq\" + 0.010*\"government\" + 0.010*\"weapon\" + 0.010*\"report\" + 0.009*\"RT\" + 0.009*\"operation\" + 0.009*\"IS\" + 0.009*\"ISIS\" + 0.009*\"State\" + 0.008*\"group\" + 0.008*\"Islamic\" + 0.007*\"fighter\" + 0.007*\"Mosul\" + 0.006*\"Russian\" + 0.006*\"coalition\" + 0.006*\"army\" + 0.006*\"Ministry\" + 0.006*\"Iraqi\" + 0.006*\"Defense\"')\n",
      "(8, '0.013*\"Ireland\" + 0.009*\"s\" + 0.007*\"Ð²\" + 0.007*\"woman\" + 0.006*\"year\" + 0.006*\"Northern\" + 0.006*\"man\" + 0.005*\"court\" + 0.005*\"family\" + 0.005*\"Charlotte\" + 0.004*\"Irish\" + 0.004*\"Scott\" + 0.004*\"father\" + 0.004*\"mother\" + 0.004*\"time\" + 0.003*\"week\" + 0.003*\"leg\" + 0.003*\"day\" + 0.003*\"Cohen\" + 0.003*\"Partners\" + 0.003*\"people\" + 0.003*\"house\" + 0.003*\"patient\" + 0.003*\"Mir\" + 0.003*\"life\" + 0.003*\"husband\" + 0.003*\"police\" + 0.003*\"video\" + 0.003*\"teammate\" + 0.003*\"pill\"')\n",
      "(1, '0.012*\"planet\" + 0.012*\"hole\" + 0.010*\"crime\" + 0.010*\"star\" + 0.010*\"space\" + 0.009*\"moon\" + 0.009*\"Earth\" + 0.008*\"Duterte\" + 0.008*\"system\" + 0.008*\"image\" + 0.007*\"object\" + 0.007*\"year\" + 0.007*\"time\" + 0.006*\"mission\" + 0.006*\"scientist\" + 0.006*\"war\" + 0.006*\"abuse\" + 0.006*\"Star\" + 0.006*\"sun\" + 0.006*\"account\" + 0.005*\"Jupiter\" + 0.005*\"NASA\" + 0.005*\"MORE\" + 0.005*\"trial\" + 0.005*\"researcher\" + 0.005*\"Shaaban\" + 0.004*\"light\" + 0.004*\"distance\" + 0.004*\"genocide\" + 0.004*\"s\"')\n",
      "(45, '0.020*\"state\" + 0.018*\"FIFA\" + 0.011*\"Texas\" + 0.010*\"Green\" + 0.008*\"lawsuit\" + 0.007*\"bill\" + 0.007*\"year\" + 0.007*\"woman\" + 0.007*\"Soros\" + 0.007*\"Oklahoma\" + 0.006*\"s\" + 0.006*\"Virginia\" + 0.006*\"Pennsylvania\" + 0.006*\"plaintiff\" + 0.006*\"ballot\" + 0.006*\"Stein\" + 0.005*\"law\" + 0.005*\"University\" + 0.005*\"executive\" + 0.005*\"Party\" + 0.005*\"complaint\" + 0.004*\"Samsung\" + 0.004*\"people\" + 0.004*\"New\" + 0.004*\"lead\" + 0.004*\"voter\" + 0.004*\"US\" + 0.004*\"time\" + 0.004*\"vote\" + 0.004*\"committee\"')\n"
     ]
    }
   ],
   "source": [
    "for topic in ldamodel.print_topics(num_words=30):\n",
    "    print (topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have tried to import the package but it did not work in python 3. So i leave my codes here to show I have tried and I got an error.. \n",
    "\n",
    "## Interactive visualisation\n",
    "!pip forge pyldavis install#it does not function.\n",
    "import pyLDAvis.gensim\n",
    "vis = pyLDAvis.gensim.prepare(ldamodel, lemmano, dictionary)\n",
    "pyLDAvis.display(vis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
